#
# This workflow is run regularly and scans for package updates, by
# downloading the file specified by the `PackageInfoURL` in each package
# and comparing it against what was there already.
#
# Then for each package where a diff is found, a new `CI` job is created,
# see `create-pull-request` below, which creates a pull request updating
# the package. Note that we perform no validation of the update here;
# that is a task for the GItHub workflow in `pull-request.yml`.
#
name: "Scan for updates"

on:
  workflow_dispatch:  # for debugging
    inputs:
      pkginfo_urls:
        description: 'A space separated list of PackageInfo.g URLs'
        required: false
        type: string
        default: ''
  schedule:
    - cron: '3 * * * *' # Every hours at 3 past

jobs:
  scan-for-updates:
    name: "Scan for package updates"
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.get-names.outputs.matrix }}
    steps:
      - uses: actions/checkout@v2

      # Cache the package archives we download across runs of this job
      # to speed up things considerably
      - name: "Cache archives"
        uses: actions/cache@v2
        with:
          path: _archives
          key: archives-${{ hashFiles('packages/*/meta.json') }}
          restore-keys: |
            archives-

      # the following step is useful for debugging
      - name: "Determine system architecture for -march=native"
        run: |
          echo "cc -march=native: $(tools/compiler_arch.sh cc)"
          echo "c++ -march=native: $(tools/compiler_arch.sh c++)"

      # Setup ccache, to speed up repeated compilation of the same binaries
      # (i.e., GAP and the packages)
      - name: "Setup ccache"
        uses: Chocobo1/setup-ccache-action@v1
        with:
          update_packager_index: false

      - name: "Install GAP"
        uses: gap-actions/setup-gap@v2
        with:
          GAP_BOOTSTRAP: 'minimal'
          GAP_PKGS_TO_CLONE: 'crypting json'
          GAP_PKGS_TO_BUILD: 'crypting json'

      - name: "Install prerequisites for package distribution tools"
        run: python -m pip install -r tools/requirements.txt

      - name: "Scan for updates"
        run: tools/scan_for_updates.py

      - name: "Import user specified packages"
        run: |
          tools/import_packages.py ${{ github.event.inputs.pkginfo_urls }}
          git add packages/

      # remove archives we don't need anymore; this reduces the size of the caches
      - name: "Cleanup archives"
        run: tools/cleanup_archives.py

      # The following builds a job matrix; we lunch a copy of the "create-pull-request"
      # for each package whose meta.json was modified by `scan_for_updates.py`
      - name: "Creates jobs for modified packages"
        id: get-names
        run: |
            modified=$(git diff --name-only --no-renames --staged --diff-filter=AM -- packages/*/meta.json)
            MATRIX="{\"package\":["
            for PKG in ${modified}; do
              PKG=${PKG%"/meta.json"}
              PKG=${PKG#"packages/"}
              echo "${PKG}"
              MATRIX="${MATRIX}\"${PKG}\","
            done
            MATRIX="${MATRIX}]}"
            echo "::set-output name=matrix::$MATRIX"
            tar cvf modified.tar.gz $modified

      - name: "Upload metadata as artifact for pull request jobs"
        uses: actions/upload-artifact@v2
        with:
          name: metadata
          path: modified.tar.gz

  create-pull-request:
    name: "Create pull request for ${{ matrix.package }}"
    if: ${{ needs.scan-for-updates.outputs.matrix != '{"package":[]}' }}
    needs: scan-for-updates
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.scan-for-updates.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v2

      - name: "Download metadata from previous job"
        uses: actions/download-artifact@v2
        with:
          name: metadata

      - name: "Extract package version"
        run: |
          tar xvf modified.tar.gz
          pkg_version=$(jq -r '.Version' < packages/${{ matrix.package }}/meta.json)
          if git ls-files | fgrep -q packages/${{ matrix.package }}/meta.json ; then
            echo "PR_TITLE=[${{ matrix.package }}] Update to ${pkg_version}" >> $GITHUB_ENV
            echo "PR_LABEL=package update" >> $GITHUB_ENV
          else
            echo "PR_TITLE=[${{ matrix.package }}] New package, version ${pkg_version}" >> $GITHUB_ENV
            echo "PR_LABEL=new package" >> $GITHUB_ENV
          fi

      - name: "Prepare PR body text"
        id: get-pr-body
        run: |
          body=$(tools/make_pr_body.py ${{ matrix.package }})
          body="${body//'%'/'%25'}"
          body="${body//$'\n'/'%0A'}"
          body="${body//$'\r'/'%0D'}"
          echo ::set-output name=body::$body

      # We set up a GitHub App in order to ensure that workflows are run on the PRs
      # created by us, following the instructions here:
      # <https://github.com/peter-evans/create-pull-request/blob/main/docs/concepts-guidelines.md#authenticating-with-github-app-generated-tokens>
      # The bot can also be set up for personal forks of this repository, for testing
      # and debugging, see <https://github.com/apps/gap-package-distribution-bot>.
      - uses: tibdex/github-app-token@v1
        id: generate-token
        with:
          app_id: ${{ secrets.APP_ID }}
          private_key: ${{ secrets.APP_PRIVATE_KEY }}

      - uses: peter-evans/create-pull-request@v4
        with:
          token: ${{ steps.generate-token.outputs.token }}
          # https://api.github.com/users/gap-package-distribution-bot%5Bbot%5D
          author: "gap-package-distribution-bot <100730870+gap-package-distribution-bot[bot]@users.noreply.github.com>"
          add-paths: packages/${{ matrix.package }}
          commit-message: "${{ env.PR_TITLE }}"
          body: ${{ steps.get-pr-body.outputs.body }}
          branch: automatic/${{ matrix.package }}
          delete-branch: true
          title: "${{ env.PR_TITLE }}"
          labels: |
            automated pr
            ${{ env.PR_LABEL }}
